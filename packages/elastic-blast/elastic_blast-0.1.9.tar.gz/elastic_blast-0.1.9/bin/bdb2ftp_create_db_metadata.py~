#!/usr/bin/env python3
"""
bdb2ftp_create_json.py - See DESC constant below

Author: Irena Zaretskaya (zaretska@ncbi.nlm.nih.gov)
Created: Fri 4 Sep 2020 02:05:56 PM EST
"""
import os
import time
import argparse
import glob
import configparser
import unittest
import logging
import json
import subprocess
import re
import datetime
from pathlib import Path
import tempfile
from dataclasses import dataclass, field
from typing import List


DFLT_LOGFILE = 'bdb2ftp_create_db_metadata.log'
FTP_HTTP_PATH = 'ftp://ftp.ncbi.nlm.nih.gov/blast/db/'

ERROR_DATABASE_INFO = 2
ERROR_DATABASE_NOT_FOUND = 1

DESC = r"""
This program creates blastdb metadata json for one database on FTP site
"""

"""
Arguments: --db [database name]
--dbpath[uncompressed database path]
--dbpath_ftp[compressed database path]
--ftp_http_path[ftp http path, default:ftp://ftp.ncbi.nlm.nih.gov/blast/db/]
--logfile [logfile, default:bdb2ftp_create_db_metadata.log]


This script 
1. Gets information for uncompressed database --db using blastdbcmd located in --dbpath
2. Gets information for compressed database --db located in --dbpath_ftp
3. Populates [db]-[dbtype]-metadata.json file for --db
#./bdb2ftp_create_db_metadata.py  -db nr  -dbpath /net/frosty/vol/blast/db/disk.blast/blast2455 -dbpath_ftp /netmnt/traces04/ftp-blast/db  -pretty -test 
#To include in update_blastdb_ftp.sh
$BIN_DIR/bdb2ftp_create_db_metadata.py -db $DB -dbpath $WORK_DIR/$PID -dbpath_ftp $DEST -pretty -logfile $DB.log
"""


@dataclass
class BlastDbFTPMetadata:
    dbname: str
    version: str = '1.1'
    dbtype: str = ''
    description: str = ''
    number_of_letters: int = 0
    number_of_sequences: int = 0
    files: List[str] = field(default_factory=list)
    last_updated: str = ''
    bytes_total: int = 0
    bytes_to_cache: int = 0
    number_of_volumes: int = 0


class BlastDbFTPMetadataEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, BlastDbFTPMetadata):
            return obj.__dict__
        else:
            return json.JSONEncoder.default(self, obj)

def get_uncompressed_db_name(db: str):
    if db == "human_genome":
        db = "GPIPE/9606/current/GCF_000001405.39_top_level"       
    elif db == "mouse_genome":
        db = "GPIPE/10090/current/GCF_000001635.27_top_level"       
    return db
    
def get_uncompressed_database_info(oneDBJson, db: Path):
    ret = 0
        
    # get number of volumes
    # this is called first to verify that we are dealing with a proper BLAST
    # database
    cmd = f'blastdbcmd -db {db} -info'.split()
    logging.info(f'Getting number of volumes for {db} CMD: {cmd}')
    try:
        p = subprocess.run(cmd, check=True, stdout = subprocess.PIPE,
                           stderr = subprocess.PIPE)

        lines = p.stdout.decode().split('\n')
        for num, line in enumerate(lines):
            if line.startswith('Volumes:'):
                oneDBJson.number_of_volumes = len(lines) - num - 2
                break

    except subprocess.CalledProcessError as err:
        logging.error(f'{err.stdout.decode().strip()}\n{err.stderr.decode().strip()}')
        return ERROR_DATABASE_INFO
    except:
        logging.error("Error: " + str(sys.exc_info()))
        return ERROR_DATABASE_INFO


    # get other database information
    # blastdbcmd -list fails for alias files and works with a directory, where
    # additional files may cause it to fail. To avoid problems we create
    # symlinks to database file in a temporary directory and work with them.
    dbfiles = db.parent.glob(f'{db.name}.*[np]??')
    with tempfile.TemporaryDirectory() as tmp:
        logging.info(f'Creating symlinks to database file in {tmp}')
        # create symlinks, dbfile.resolve() finds an absolute path
        for dbfile in dbfiles:
            (Path(tmp) / dbfile.name).symlink_to(dbfile.resolve())

        cmd = f'blastdbcmd -list {tmp} -remove_redundant_dbs -list_outfmt'.split() +  ['%f\t%p\t%t\t%l\t%n\t%d\t%U']
        logging.info("Getting uncompressed database " + str(db) + " information. CMD: " + ' '.join(cmd))
        try:
            p = subprocess.run(cmd, check=True, stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE)

            for line in p.stdout.decode().split('\n'):
                fields = line.rstrip().split('\t')
                if os.path.basename(fields[0]) != db.name:
                    continue

                oneDBJson.dbtype = fields[1]
                oneDBJson.description = fields[2]
                oneDBJson.number_of_letters = int(fields[3])
                oneDBJson.number_of_sequences = int(fields[4])
                oneDBJson.last_updated = fields[5]
                oneDBJson.bytes_total = int(fields[6])
                break
        except subprocess.CalledProcessError as err:
            logging.error(f'{err.stdout.decode().strip()}\n{err.stderr.decode().strip()}')
            return ERROR_DATABASE_INFO
        except ValueError as err:
            logging.error(f'Error when parsing database informtation: {err}')
            return ERROR_DATABASE_INFO
        except:
            logging.error("Error: " + str(sys.exc_info()))
            return ERROR_DATABASE_INFO

    ret = populate_db_info(oneDBJson, db, "uncompressed")
            
    if ret == 0:
        ret = populate_db_info(oneDBJson, db, "dbcache")

    if ret == 0:
        logging.info("Success getting uncompressed database " + str(db) + " information.")
    return ret

    
def populate_db_info(oneDBJson, db: Path, info_type):
    if info_type == 'uncompressed':
        pattern = '.*'
    else: #"dbcache"
        dbtype = oneDBJson.dbtype[0].lower()
        pattern = '.*' + dbtype + '[si][qn]'

    returncode = 0                
    fileFound = False       
    
    logging.info("Searching " + str(db)  + pattern)
    for f in glob.glob(str(db) + pattern):
        if not os.path.islink(f):
            if info_type == 'uncompressed':
                filename_parts = os.path.splitext(f)
                if filename_parts[1] == ".md5" or filename_parts[1] == ".gz":
                    continue
                oneDBJson.files.append(os.path.basename(f))
            else:
                oneDBJson.bytes_to_cache += os.stat(f).st_size
            fileFound = True                
            
    if not fileFound:
        logging.error("Error: " + info_type + " database " + str(db) + pattern + " not found in " + str(db.parent))
        returncode = ERROR_DATABASE_NOT_FOUND
        
    return returncode


def main():
    """ Entry point into this program. """
    parser = create_arg_parser()
    args = parser.parse_args()
        
    config_logging(args)

    db = Path(args.db)
    # save user provided database name and do NCBI conversion for selected
    # database names
    orig_dbname = db.name
    db = db.parent / get_uncompressed_db_name(db.name)

    file_name = orig_dbname + "-"
    logging.info("Creating metadata json file for" + file_name + " created")
    oneDBJson = BlastDbFTPMetadata(orig_dbname)
    if db.name != 'taxdb':
        ret = get_uncompressed_database_info(oneDBJson, db)
        file_name += oneDBJson.dbtype[0:4].lower() + '-metadata.json'        
    else: #taxdb
        oneDBJson.description = 'Taxonomy database'
        ret = populate_db_info(oneDBJson,args,"uncompressed")    
        if ret == 0:    
            ret = populate_db_info(oneDBJson,args,"compressed")    
        file_name += 'metadata.json'
    if ret == 0:                
        output = json.dumps(oneDBJson, cls=BlastDbFTPMetadataEncoder, sort_keys=False)
        #rename '_' to '-' in keys
        dict = json.loads(output)
        current_keys = list(dict.keys())
        for current_key in current_keys:
            new_key = current_key.replace('_','-')
            dict[new_key] = dict.pop(current_key)
        if args.pretty:
            output = json.dumps(dict,sort_keys=False, indent=2)
        else:
            output = json.dumps(dict,sort_keys=False)
                        
        f = open(file_name,"w")                
        print(output, file=f)            
        f.close()   
        logging.info("Metadata json file " + file_name + " created")    
           
    return ret

def create_arg_parser():
    """ Create the command line options parser object for this script. """
    parser = argparse.ArgumentParser(description=DESC)    
    parser.add_argument("-db", type=str, help="A BLAST database", required=True)
    parser.add_argument("-pretty", action='store_true', help="Pretty-print JSON output")
    parser.add_argument("-v", "--verbose", action="count", default=0, help="Increase output verbosity")
    parser.add_argument("-logfile", default=DFLT_LOGFILE,help="Default: " + DFLT_LOGFILE)
    parser.add_argument("-loglevel", default='INFO',choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"])
    return parser


def config_logging(args):
    if args.logfile == 'stderr':
        logging.basicConfig(level=str2ll(args.loglevel),
                            format="%(asctime)s %(message)s")
    else:
        logformat_for_file = "%(asctime)s %(levelname)s: %(message)s"
        logformat_for_stderr = "%(levelname)s: %(message)s"

        logger = logging.getLogger()
        logger.setLevel(str2ll(args.loglevel))

        # to stderr
        handler = logging.StreamHandler()
        handler.setLevel(logging.WARNING)
        handler.setFormatter(logging.Formatter(logformat_for_stderr))
        logger.addHandler(handler)

        # to a file
        handler = logging.FileHandler(args.logfile, mode='a')
        handler.setLevel(str2ll(args.loglevel))
        handler.setFormatter(logging.Formatter(logformat_for_file))
        logger.addHandler(handler)


    logging.logThreads = 0
    logging.logProcesses = 0
    logging._srcfile = None


def str2ll(level):
    """ Converts the log level argument to a numeric value.

    Throws an exception if conversion can't be done.
    Copied from the logging howto documentation
    """
    retval = getattr(logging, level.upper(), None)
    if not isinstance(retval, int):
        raise ValueError('Invalid log level: %s' % level)
    return retval


if __name__ == "__main__":
    import sys
    sys.exit(main())

