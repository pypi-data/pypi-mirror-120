# Copyright 2021 Albert Garcia
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
DSET extended from DSNT (soft-argmax) operations for use in PyTorch computation graphs.
"""

__version__ = "0.1.6"
__author__ = 'Albert Garcia'
__credits__ = 'SnT - Interdisciplinary Centre for Security, Reliability and Trust'


from functools import reduce
from operator import mul

import torch
import torch.nn.functional

import numpy as np
from scipy.stats import multivariate_normal
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse


def linear_expectation(probs, values):
    assert(len(values) == probs.ndimension() - 2)
    expectation = []
    for i in range(2, probs.ndimension()):
        # Marginalise probabilities
        marg = probs
        for j in range(probs.ndimension() - 1, 1, -1):
            if i != j:
                marg = marg.sum(j, keepdim=False)
        # Calculate expectation along axis `i`
        expectation.append((marg * values[len(expectation)]).sum(-1, keepdim=False))
    return torch.stack(expectation, -1)


def normalized_linspace(length, dtype=None, device=None):
    """Generate a vector with values ranging from -1 to 1.

    Note that the values correspond to the "centre" of each cell, so
    -1 and 1 are always conceptually outside the bounds of the vector.
    For example, if length = 4, the following vector is generated:

    ```text
     [ -0.75, -0.25,  0.25,  0.75 ]
     ^              ^             ^
    -1              0             1
    ```

    Args:
        length: The length of the vector

    Returns:
        The generated vector
    """
    if isinstance(length, torch.Tensor):
        length = length.to(device, dtype)
    first = -(length - 1.0) / length
    return torch.arange(length, dtype=dtype, device=device) * (2.0 / length) + first


def soft_argmax(heatmaps, normalized_coordinates=True):
    if normalized_coordinates:
        values = [normalized_linspace(d, dtype=heatmaps.dtype, device=heatmaps.device)
                  for d in heatmaps.size()[2:]]
    else:
        values = [torch.arange(0, d, dtype=heatmaps.dtype, device=heatmaps.device)
                  for d in heatmaps.size()[2:]]
    coords = linear_expectation(heatmaps, values)
    # We flip the tensor like this instead of using `coords.flip(-1)` because aten::flip is not yet
    # supported by the ONNX exporter.
    coords = torch.cat(tuple(reversed(coords.split(1, -1))), -1)
    return coords


def dsnt(heatmaps, **kwargs):
    """Differentiable spatial to numerical transform.

    Args:
        heatmaps (torch.Tensor): Spatial representation of locations

    Returns:
        Numerical coordinates corresponding to the locations in the heatmaps.
    """
    return soft_argmax(heatmaps, **kwargs)


def sharpen_heatmaps(heatmaps, alpha):
    """Sharpen heatmaps by increasing the contrast between high and low probabilities.

    Example:
        Approximate the mode of heatmaps using the approach described by Equation 1 of
        "FlowCap: 2D Human Pose from Optical Flow" by Romero et al.)::

            coords = soft_argmax(sharpen_heatmaps(heatmaps, alpha=6))

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model
        alpha (float): Sharpness factor. When ``alpha == 1``, the heatmaps will be unchanged. Use
        ``alpha > 1`` to actually sharpen the heatmaps.

    Returns:
        The sharpened heatmaps.
    """
    sharpened_heatmaps = heatmaps ** alpha
    sharpened_heatmaps /= sharpened_heatmaps.flatten(2).sum(-1)
    return sharpened_heatmaps


def flat_softmax(inp):
    """Compute the softmax with all but the first two tensor dimensions combined."""

    orig_size = inp.size()
    flat = inp.view(-1, reduce(mul, orig_size[2:]))
    flat = torch.nn.functional.softmax(flat, -1)
    return flat.view(*orig_size)


def euclidean_losses(actual, target):
    """Calculate the Euclidean losses for multi-point samples.

    Each sample must contain `n` points, each with `d` dimensions. For example,
    in the MPII human pose estimation task n=16 (16 joint locations) and
    d=2 (locations are 2D).

    Args:
        actual (Tensor): Predictions (B x L x D)
        target (Tensor): Ground truth target (B x L x D)


    Returns:
        Tensor: Losses (B x L)
    """
    assert actual.size() == target.size(), 'input tensors must have the same size'
    return torch.norm(actual - target, p=2, dim=-1, keepdim=False)


def l1_losses(actual, target):
    """Calculate the average L1 losses for multi-point samples.

    Args:
        actual (Tensor): Predictions (B x L x D)
        target (Tensor): Ground truth target (B x L x D)

    Returns:
        Tensor: Losses (B x L)
    """
    assert actual.size() == target.size(), 'input tensors must have the same size'
    return torch.nn.functional.l1_loss(actual, target, reduction='none').mean(-1)


def mse_losses(actual, target):
    """Calculate the average squared L2 losses for multi-point samples.

    Args:
        actual (Tensor): Predictions (B x L x D)
        target (Tensor): Ground truth target (B x L x D)

    Returns:
        Tensor: Losses (B x L)
    """
    assert actual.size() == target.size(), 'input tensors must have the same size'
    return torch.nn.functional.mse_loss(actual, target, reduction='none').mean(-1)


def make_gauss(means, size, sigma, normalize=True):
    """Draw Gaussians.

    This function is differential with respect to means.

    Note on ordering: `size` expects [..., depth, height, width], whereas
    `means` expects x, y, z, ...

    Args:
        means: coordinates containing the Gaussian means (units: normalized coordinates)
        size: size of the generated images (units: pixels)
        sigma: standard deviation of the Gaussian (units: pixels)
        normalize: when set to True, the returned Gaussians will be normalized
    """

    dim_range = range(-1, -(len(size) + 1), -1)
    coords_list = [normalized_linspace(s, dtype=means.dtype, device=means.device)
                   for s in reversed(size)]

    # PDF = exp(-(x - \mu)^2 / (2 \sigma^2))

    # dists <- (x - \mu)^2
    dists = [(x - mean) ** 2 for x, mean in zip(coords_list, means.split(1, -1))]

    # ks <- -1 / (2 \sigma^2)
    stddevs = [2 * sigma / s for s in reversed(size)]
    ks = [-0.5 * (1 / stddev) ** 2 for stddev in stddevs]

    exps = [(dist * k).exp() for k, dist in zip(ks, dists)]

    # Combine dimensions of the Gaussian
    gauss = reduce(mul, [
        reduce(lambda t, d: t.unsqueeze(d), filter(lambda d: d != dim, dim_range), dist)
        for dim, dist in zip(dim_range, exps)
    ])

    if not normalize:
        return gauss

    # Normalize the Gaussians
    val_sum = reduce(lambda t, dim: t.sum(dim, keepdim=True), dim_range, gauss) + 1e-24
    return gauss / val_sum


def average_loss(losses, mask=None):
    """Calculate the average of per-location losses.

    Args:
        losses (Tensor): Predictions (B x L)
        mask (Tensor, optional): Mask of points to include in the loss calculation
            (B x L), defaults to including everything
    """

    if mask is not None:
        assert mask.size() == losses.size(), 'mask must be the same size as losses'
        losses = losses * mask
        denom = mask.sum()
    else:
        denom = losses.numel()

    # Prevent division by zero
    if isinstance(denom, int):
        denom = max(denom, 1)
    else:
        denom = denom.clamp(1)

    return losses.sum() / denom


def _kl(p, q, ndims):
    eps = 1e-24
    unsummed_kl = p * ((p + eps).log() - (q + eps).log())
    kl_values = reduce(lambda t, _: t.sum(-1, keepdim=False), range(ndims), unsummed_kl)
    return kl_values


def _js(p, q, ndims):
    m = 0.5 * (p + q)
    return 0.5 * _kl(p, m, ndims) + 0.5 * _kl(q, m, ndims)


def _divergence_reg_losses(heatmaps, mu_t, sigma_t, divergence):
    ndims = mu_t.size(-1)
    assert heatmaps.dim() == ndims + 2, 'expected heatmaps to be a {}D tensor'.format(ndims + 2)
    assert heatmaps.size()[:-ndims] == mu_t.size()[:-1]

    gauss = make_gauss(mu_t, heatmaps.size()[2:], sigma_t)
    divergences = divergence(heatmaps, gauss, ndims)
    return divergences


def kl_reg_losses(heatmaps, mu_t, sigma_t):
    """Calculate Kullback-Leibler divergences between heatmaps and target Gaussians.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model
        mu_t (torch.Tensor): Centers of the target Gaussians (in normalized units)
        sigma_t (float): Standard deviation of the target Gaussians (in pixels)

    Returns:
        Per-location KL divergences.
    """

    return _divergence_reg_losses(heatmaps, mu_t, sigma_t, _kl)


def js_reg_losses(heatmaps, mu_t, sigma_t):
    """Calculate Jensen-Shannon divergences between heatmaps and target Gaussians.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model
        mu_t (torch.Tensor): Centers of the target Gaussians (in normalized units)
        sigma_t (float): Standard deviation of the target Gaussians (in pixels)

    Returns:
        Per-location JS divergences.
    """

    return _divergence_reg_losses(heatmaps, mu_t, sigma_t, _js)


def variance_reg_losses(heatmaps, sigma_t):
    """Calculate the loss between heatmap variances and target variance.

    Note that this is slightly different from the version used in the
    DSNT paper. This version uses pixel units for variance, which
    produces losses that are larger by a constant factor.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model
        sigma_t (float): Target standard deviation (in pixels)

    Returns:
        Per-location sum of square errors for variance.
    """

    # mu = E[X]
    values = [normalized_linspace(d, dtype=heatmaps.dtype, device=heatmaps.device)
              for d in heatmaps.size()[2:]]
    mu = linear_expectation(heatmaps, values)
    # var = E[(X - mu)^2]
    values = [(a - b.squeeze(0)) ** 2 for a, b in zip(values, mu.split(1, -1))]
    var = linear_expectation(heatmaps, values)


    heatmap_size = torch.tensor(list(heatmaps.size()[2:]), dtype=var.dtype, device=var.device)
    actual_variance = var * (heatmap_size / 2) ** 2
    target_variance = sigma_t ** 2
    sq_error = (actual_variance - target_variance) ** 2

    return sq_error.sum(-1, keepdim=False)


def normalized_to_pixel_coordinates(coords, size):
    """Convert from normalized coordinates to pixel coordinates.

    Args:
        coords: Coordinate tensor, where elements in the last dimension are ordered as (x, y, ...).
        size: Number of pixels in each spatial dimension, ordered as (..., height, width).

    Returns:
        `coords` in pixel coordinates.
    """
    if torch.is_tensor(coords):
        size = size.clone().flip(-1)
    return 0.5 * ((coords + 1) * size - 1)


def pixel_to_normalized_coordinates(coords, size):
    """Convert from pixel coordinates to normalized coordinates.

    Args:
        coords: Coordinate tensor, where elements in the last dimension are ordered as (x, y, ...).
        size: Number of pixels in each spatial dimension, ordered as (..., height, width).

    Returns:
        `coords` in normalized coordinates.
    """
    if torch.is_tensor(coords):
        size = size.clone().flip(-1)
    return ((2 * coords + 1) / size) - 1



#################################################### DSET Extension ###########################################################


def linear_expectation_covariance(heatmaps, aux_values):
    # Duplicate each vector (X-mu_x) and (Y-mu_y) into matrices
    # This is done since the covariance computation cannot be vectorized like in the variances computations
    aux_values[0] = aux_values[0].unsqueeze(-1).repeat(1, 1, 1, heatmaps.size()[-1])
    aux_values[1] = aux_values[1].unsqueeze(-2).repeat(1, 1, heatmaps.size()[-2], 1)

    # Do (X-mu_x) * (Y-mu_y)
    aux_values = aux_values[0] * aux_values[1]
    assert(aux_values.size() == heatmaps.size()),'The size of the heatmaps '+str(heatmaps.size())+' is not equal to those of the aux_values '+str(aux_values.size())
    return (heatmaps * aux_values).sum(dim=(-2,-1))


def compute_heatmaps_statistics(heatmaps, pixel_units = False):
    """Calculate the expectation, variance and covariance of each heatmap.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model with shape [B, E, H, W]
        pixel_units (bool, default = False): If True then returns all values in pixels otherwise return expectation in normalized coordinates while variance and covariance are returned in relative values.

    Returns:
        Expectetions, variances and covariances for each Ellipse E within each batch image B.
    """

    # mu = E[X]
    values = [normalized_linspace(d, dtype=heatmaps.dtype, device=heatmaps.device)
              for d in heatmaps.size()[2:]]

    mu = linear_expectation(heatmaps, values)

    aux_values = [(a - b.squeeze(0)) for a, b in zip(values, mu.split(1, -1))]

    # var = E[(X - mu)^2]
    var_values = [x ** 2 for x in aux_values]
    var = linear_expectation(heatmaps, var_values)

    # cov = E[(X - mu_x)*(Y - mu_y)]
    cov = linear_expectation_covariance(heatmaps, aux_values)

    # We flip the tensors like this instead of using `coords.flip(-1)` because aten::flip is not yet
    # supported by the ONNX exporter.
    mu = torch.cat(tuple(reversed(mu.split(1, -1))), -1)
    var = torch.cat(tuple(reversed(var.split(1,-1))), -1)
    
    # If we want the output in pixel units (not normalized/relative) then scale them with the heatmap size
    if pixel_units:
        heatmaps_size_array = list(heatmaps.size()[2:])
        heatmap_size = torch.tensor(heatmaps_size_array, dtype=var.dtype, device=var.device)
        heatmap_size_reversed = torch.tensor(heatmaps_size_array[::-1], dtype=var.dtype, device=var.device)
        var = var * (heatmap_size_reversed / 2) ** 2
        cov = cov * (heatmap_size[0] / 2) * (heatmap_size[1] / 2)
        mu = normalized_to_pixel_coordinates(mu, heatmap_size)

    return mu, var, cov


def construct_covariance_matrices(var, cov):
    """Construct all covariance matrices of a batch.

    Args:
        var (torch.Tensor): Variances computed from the heatmaps with shape [B, E, 2]
        cov (torch.Tensor): Covariances computed from the heatmaps with shape [B, E]

    Returns:
        Tensor containing all the covariances matrices with shape [B, E, 2, 2]
    """
    
    batches, locations = var.size()[0:2]
    all_sigmas = []
    
    for batch_num in range(batches):
        batch_sigmas = []
        
        for location_num in range(locations):
            sigma = torch.diag(var[batch_num, location_num, :])
            sigma[0,1] = sigma[1,0] = cov[batch_num, location_num]
            batch_sigmas.append(sigma)
        
        batch_sigmas =  torch.stack(batch_sigmas, dim=0)
        all_sigmas.append(batch_sigmas)
    
    return torch.stack(all_sigmas, dim=0)


def covariance_matrices_to_parameters(sigmas, sort_ellipse_axis=True):
    """Compute the axes and rotation from all covariance matrices of a batch.

    Args:
        sigmas (torch.Tensor): Covariances matrices with shape [B, E, 2, 2]
        sort_ellipse_axis (bool, default=True): Whether to sort the ellipse axes lengths in descending order when computing them through eigenvalue decomposition

    Returns:
        Tensor containing all the extracted parameters (axis_1, axis_2, theta [rads]) with shape [B, E, 3]
    """
    
    batches, locations = sigmas.size()[0:2]
    all_params = []
    
    for batch_num in range(batches):
        batch_params = []
        
        for location_num in range(locations):
            D, R = torch.eig(sigmas[batch_num, location_num, :, :], eigenvectors=True)
            axes = torch.sqrt(torch.abs(D))[:,0] # First column is the real part, second the imaginary part
            
            if sort_ellipse_axis and axes[0] < axes[1]:
                axes[[0, 1]] = axes[[1, 0]] # swap ellipse axes
                R[:, [0, 1]] = R[:, [1, 0]] # swap columns
                if torch.linalg.det(R) < 0: R[:,0] = -R[:,0] # if determinant -1 then swap sign of first column
                cos, sin = R[0,0], R[1,0]
                theta = torch.atan2(sin, cos)
                if theta > np.pi/2 or theta < -np.pi/2: # if theta outside [-pi/2, pi/2] then change sign of R and recompute theta
                    R = -R
                    cos, sin = R[0,0], R[1,0]
                    theta = torch.atan2(sin, cos)
                theta = theta.unsqueeze(0)
            else:
                cos, sin = R[0,0], R[1,0]
                theta = torch.atan2(sin, cos).unsqueeze(0)
            batch_params.append( torch.cat( (axes, theta) ) )
        
        batch_params =  torch.stack(batch_params, dim=0)
        all_params.append(batch_params)
    
    return torch.stack(all_params, dim=0)
    

def plot_ellipse_from_covariance_matrix(center, sigma, original_heatmap, alpha_heatmap=1.0, heatmap_cmap='gray', color='r'):
    """Plot the ellipse derived from the center and the covariance matrix 'sigma' along with the original heatmap.
    If a batch of centers or a batch of sigmas is given, then only the first sample will be plotted.

    Args:
        center (torch.Tensor): Center tensor of the ellipse with shape [2]
        sigmas (torch.Tensor): Covariance matrix of the heatmap with shape [2, 2]
        original_heatmap (torch.Tensor): Heatmap with shape [H, W]
        alpha_heatmap (float): Float between 0 and 1 to apply transparency to the plotted heatmap
        heatmap_cmap (String): Color map to be used for the heatmap

    Returns:
        Matplotlib plot with the derived ellipse and the heatmap.

    """

    if isinstance(center, torch.Tensor):
        center = center.detach().numpy()
    if len(center.shape) == 3:
        center = center[0,0]
    if isinstance(sigma, np.ndarray):
        sigma = torch.Tensor(sigma)
    if len(sigma.shape) == 4:
        sigma = sigma[0,0]
    if len(sigma.shape) == 2:
        sigma = sigma.unsqueeze(0).unsqueeze(0)
    
    params = covariance_matrices_to_parameters(sigma)
#     print('Axes and theta:', params)
    angle_deg = np.rad2deg(params[0,0,2])
#     print('Theta (deg):', angle_deg.item())
    axes = params[0,0,0:2]
    plot_axes = plt.gca()
    e = Ellipse(xy=center, width=axes[0]*2, height=axes[1]*2,
                angle=angle_deg, edgecolor=color, linestyle='-',
                linewidth=2, fill=False)
    plot_axes.add_artist(e)

    if len(original_heatmap.shape) == 4:
        original_heatmap = original_heatmap[0,0]
    
    plt.scatter(*center, c=color)
    plt.imshow(original_heatmap, cmap=heatmap_cmap, alpha=alpha_heatmap)


def gaussian_heatmap(heatmap_size, mean, cov, normalize=True, return_tensor=True):
    """Generate a Gaussian heatmap with specific mean and covariance matrix.

    Args:
        heatmap_size (torch.Tensor): Heatmap size to be generated [H, W]
        mean (torch.Tensor): Mean values with shape [2]
        cov (torch.Tensor): Covariance matrix with shape [2, 2]
        normalize (bool, default = True): Whether to normalize the generated heatmap
        return_tensor (bool, default = True): Whether to return PyTorch Tensor instead of Numpy array

    Returns:
        Tensor containing all the Gaussian heatmaps with shape [B, E, H, W]
    """
    x = np.arange(0, heatmap_size[1], 1)
    y = np.arange(0, heatmap_size[0], 1)
    xx, yy = np.meshgrid(x, y)
    points = np.stack((xx, yy), axis=-1)
    pdf = multivariate_normal.pdf(points, mean=mean, cov=cov)
    if normalize: pdf = pdf / pdf.sum()
    if return_tensor: pdf = torch.from_numpy(pdf)
    return pdf


def generate_gaussian_heatmaps(heatmap_size, means, sigmas, normalize=True, return_tensor=True):
    """Generate all the Gaussian heatmaps from a batch of means and covariance matrices.

    Args:
        heatmap_size (torch.Tensor): Heatmap size to be generated [H, W]
        means (torch.Tensor): Means values with shape [B, E, 2]
        sigmas (torch.Tensor): Covariances matrices with shape [B, E, 2, 2]
        normalize (bool, default = True): Whether to normalize the generated heatmaps
        return_tensor (bool, default = True): Whether to return PyTorch Tensor instead of Numpy array

    Returns:
        Tensor containing all the Gaussian heatmaps with shape [B, E, H, W]
    """
    
    batches, locations = means.size()[0:2]
    all_heatmaps = []
    
    for batch_num in range(batches):
        batch_heatmaps = []
        
        for location_num in range(locations):
            heatmap = gaussian_heatmap(heatmap_size, means[batch_num, location_num], sigmas[batch_num, location_num], normalize=normalize, return_tensor=return_tensor)
            
            batch_heatmaps.append( heatmap )
        
        batch_heatmaps =  torch.stack(batch_heatmaps, dim=0)
        all_heatmaps.append( batch_heatmaps )
    
    return torch.stack(all_heatmaps, dim=0)


def normalized_cov_mtx_to_cov_mtx(cov, size):
    """Convert from normalized covariance matrix to pixel covariance matrix.

    Args:
        cov (torch.Tensor): Normalized covariance matrix with shape [2, 2]
        size (torch.Tensor): Target size to be scaled [H, W]

    Returns:
        Covariance tensor in pixel units with shape [2, 2]
    """
    scaling_mtx = (size.flip(0))*2
    scaling_mtx = scaling_mtx.unsqueeze(-1)
    scaling_mtx = scaling_mtx * scaling_mtx.transpose(0,1)
    return cov * scaling_mtx


def cov_mtx_to_normalized_cov_mtx(cov, size):
    """Convert from covariance matrix in pixels to normalized covariance matrix.

    Args:
        cov (torch.Tensor): Pixel covariance matrix with shape [2, 2]
        size (torch.Tensor): Target size to be considered for normalization [H, W]

    Returns:
        Covariance tensor in normalized units with shape [2, 2]
    """
    scaling_mtx = (size.flip(0))*2
    scaling_mtx = scaling_mtx.unsqueeze(-1)
    scaling_mtx = scaling_mtx * scaling_mtx.transpose(0,1)
    return cov / scaling_mtx

#-------------------------------- SUPPORT FUNCTIONS FOR GAUSSIAN HEATMAP COMPLETION --------------------------------#

def opposite_coordinates(center_coords, selected_coords):
    coords_distance = center_coords - selected_coords
    return selected_coords + 2*coords_distance

def is_coords_inside(coords, filled_values):
    if coords[0]<0 or coords[0]>=filled_values.shape[0]: return False
    if coords[1]<0 or coords[1]>=filled_values.shape[1]: return False
    return filled_values[coords[0], coords[1]]==1

def is_coords_inside_soft(coords, filled_values, kernel_radius):
    if coords[0]-kernel_radius<0 or coords[0]+kernel_radius>=filled_values.shape[0]: return False
    if coords[1]-kernel_radius<0 or coords[1]+kernel_radius>=filled_values.shape[1]: return False
    return (filled_values[coords[0]-kernel_radius : coords[0]+kernel_radius+1, coords[1]-kernel_radius : coords[1]+kernel_radius+1]==1).any()

def is_coords_inside_extended_heatmap(coords, ext_h, ext_w):
    return coords[0] >= 0 and coords[0] < ext_h and coords[1] >= 0 and coords[1] < ext_w

def create_gaussian_kernel(M, std, sym=True):
    if M < 1:
        return torch.Tensor([])
    if M == 1:
        return torch.ones((1))
    odd = M % 2
    if not sym and not odd:
        M = M + 1
    n = torch.arange(0, M) - (M - 1.0) / 2.0
    sig2 = 2 * std * std
    w = torch.exp(-n ** 2 / sig2)
    if not sym and not odd:
        w = w[:-1]
        
    # Go from 1D to 2D Gaussian kernel
    w = w.unsqueeze(0)
    w = w * w.T
    w = w/w.sum()
    return w

def create_uniform_kernel(size):
    w = torch.ones( (size, size) )
    w = w/w.sum()
    return w

def create_reverse_gaussian(M, std, sym=True):
    w = create_gaussian_kernel(M, std, sym=sym)
    w = -w + w.max()
    w = w / w.sum()
    return w

def apply_kernel(window, kernel):
    return (window*kernel).sum()

#-------------------------------------------------------------------------------------------------------------------#

def gaussian_symmetric_lines_completion(generated_heatmap, padding_target=None, symmetrize_original_heatmap=True, num_iters=0, num_iters_soft=1, kernel_radius=3, kernel_std=0.0, auto_increment_kernel=True, return_filled=False, normalize=True):
    """Perform Gaussian completion on a heatmap based on the symmetric lines that cross the center of the Gaussian distribution (maximum pixel).

    Args:
        generated_heatmap (torch.Tensor): Heatmap containing a Gaussian distribution to be completed/extended with shape [H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H).
        symmetrize_original_heatmap (bool, default = False): Whether to start by symmetrizing all the pixels within the input heatmap. This step is enough in case the distribution's center is not close to one of the corners of the image.
        num_iters (int, default = 1): Number of times to repeat the process of trying to fill all rows and columns if possible given the all the filled pixels. This process converges to a stationary state where there are no more pixels to be filled (and thus the remaining iterations are ignored).
        num_iters_soft (int, default = 1): Number of times to repeat the process of trying to fill all rows and columns if possible by applying a kernel at the opposite coordinates.
        kernel_radius (int, default = 3): Number of pixels to be used as radius for constructing the kernel to apply during the soft iterations (kernel size = 2*kernel_radius + 1).
        kernel_std (float, default = 0.0): The std to be used for constructing the kernel to apply during the soft iterations. If std=0.0 then a uniform kernel is applied otherwise an inverted Gaussian kernel is applied.
        auto_increment_kernel (bool, default = True): Whether to increment the kernel_radius by 1 each time the soft iterations converge to a stationary state (no more pixels can be filled). By doing this, the soft iterations can keep on filling farther pixels.
        return_filled (bool, default = True): Whether to return a boolean mask with all the pixels that have been filled over the extended heatmap.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        extended_gaussian_heatmap (torch.Tensor): Extended heatmap containing a completed Gaussian distribution with shape [top + H + bottom, left + W + right]
        filled_values (torch.Tensor): Optional boolean mask with all the pixels that have been filled over the extended heatmap with shape [top + H + bottom, left + W + right]
    """
    
    h, w = generated_heatmap.shape[-2:]
    
    # Compute the zero-padded heatmap as well as auxiliary variables
    if padding_target is None: padding_target = (w,w,h,h)
    extended_gaussian_heatmap = torch.nn.functional.pad(generated_heatmap, padding_target)
    ext_h, ext_w = extended_gaussian_heatmap.shape[-2:]
    original_center = padding_target[2], padding_target[0]
    
    # Generate the boolean mask of filled pixels
    filled_values = torch.zeros(extended_gaussian_heatmap.shape)
    filled_values[original_center[0]:original_center[0]+h, original_center[1]:original_center[1]+w] = 1
    
    # Detect the center of the distribution (peak pixel)
    gaussian_center = extended_gaussian_heatmap.argmax()
    gaussian_center = torch.Tensor( [gaussian_center//ext_w, gaussian_center%ext_w] )

    # Perform filling based on all the pixels that are available within the original heatmaps
    if symmetrize_original_heatmap:
        for i in range(padding_target[2], padding_target[2]+h):
            for j in range(padding_target[0], padding_target[0]+w):
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside_extended_heatmap(opposite_coords, ext_h, ext_w)
                if is_opposite_valid:
                    extended_gaussian_heatmap[opposite_coords[0], opposite_coords[1]] = extended_gaussian_heatmap[i, j]
                    filled_values[opposite_coords[0], opposite_coords[1]] = 1

    # Iterate several times to fill the heatmap
    for n in range(num_iters):
        
        count_filled = 0
        
        # Fill all rows on top of original heatmap
        for i in range(padding_target[2]-1, -1, -1):
            any_pixel_copied = False
            for j in range(ext_w):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside(opposite_coords, filled_values)
                if is_opposite_valid:
                    extended_gaussian_heatmap[i, j] = extended_gaussian_heatmap[opposite_coords[0], opposite_coords[1]]
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
            if not any_pixel_copied: break

        # Fill all rows on bottom of original heatmap
        for i in range(padding_target[2]+h, ext_h):
            any_pixel_copied = False
            for j in range(ext_w):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside(opposite_coords, filled_values)
                if is_opposite_valid:
                    extended_gaussian_heatmap[i, j] = extended_gaussian_heatmap[opposite_coords[0], opposite_coords[1]]
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
            if not any_pixel_copied: break

        # Fill all columns on left of original heatmap
        for j in range(padding_target[0]-1, -1, -1):
            any_pixel_copied = False
            for i in range(padding_target[2], padding_target[2]+h):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside(opposite_coords, filled_values)
                if is_opposite_valid:
                    extended_gaussian_heatmap[i, j] = extended_gaussian_heatmap[opposite_coords[0], opposite_coords[1]]
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
            if not any_pixel_copied: break

        # Fill all columns on right of original heatmap
        for j in range(padding_target[0]+w, ext_w):
            any_pixel_copied = False
            for i in range(padding_target[2], padding_target[2]+h):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside(opposite_coords, filled_values)
                if is_opposite_valid:
                    extended_gaussian_heatmap[i, j] = extended_gaussian_heatmap[opposite_coords[0], opposite_coords[1]]
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
            if not any_pixel_copied: break
        
        if count_filled == 0: break
        
    #########################################################################################
    
    # Iterate several times to fill the heatmap using soft verison (3x3 kernel average)
    for n in range(num_iters_soft):
        assert kernel_radius>0,'Kernel radius needs to be defined positive'
        assert isinstance(kernel_radius, int),'Kernel radius needs to be an integer'
        
        # Generate the kernel to be used
        if kernel_std>0:
            kernel = create_reverse_gaussian((2*kernel_radius+1), kernel_std, sym=True)
        else:
            kernel = create_uniform_kernel((2*kernel_radius+1))
            
        count_filled = 0
        
        # Fill all rows on top of original heatmap
        for i in range(padding_target[2]-1, -1, -1):
            any_pixel_copied = False
            for j in range(ext_w):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside_soft(opposite_coords, filled_values, kernel_radius)
                if is_opposite_valid:
                    window = extended_gaussian_heatmap[opposite_coords[0]-kernel_radius : opposite_coords[0]+kernel_radius+1, opposite_coords[1]-kernel_radius : opposite_coords[1]+kernel_radius+1]
                    value = apply_kernel(window, kernel)
                    extended_gaussian_heatmap[i, j] = value
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
        
        # Fill all rows on bottom of original heatmap
        for i in range(padding_target[2]+h, ext_h):
            any_pixel_copied = False
            for j in range(ext_w):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside_soft(opposite_coords, filled_values, kernel_radius)
                if is_opposite_valid:
                    window = extended_gaussian_heatmap[opposite_coords[0]-kernel_radius : opposite_coords[0]+kernel_radius+1, opposite_coords[1]-kernel_radius : opposite_coords[1]+kernel_radius+1]
                    value = apply_kernel(window, kernel)
                    extended_gaussian_heatmap[i, j] = value
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
        
        # Fill all columns on left of original heatmap
        for j in range(padding_target[0]-1, -1, -1):
            any_pixel_copied = False
            for i in range(padding_target[2], padding_target[2]+h):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside_soft(opposite_coords, filled_values, kernel_radius)
                if is_opposite_valid:
                    window = extended_gaussian_heatmap[opposite_coords[0]-kernel_radius : opposite_coords[0]+kernel_radius+1, opposite_coords[1]-kernel_radius : opposite_coords[1]+kernel_radius+1]
                    value = apply_kernel(window, kernel)
                    extended_gaussian_heatmap[i, j] = value
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1

        # Fill all columns on right of original heatmap
        for j in range(padding_target[0]+w, ext_w):
            any_pixel_copied = False
            for i in range(padding_target[2], padding_target[2]+h):
                if filled_values[i, j]==1: continue
                selected_coords = torch.Tensor( [i, j] )
                opposite_coords = opposite_coordinates(gaussian_center, selected_coords).long()
                is_opposite_valid = is_coords_inside_soft(opposite_coords, filled_values, kernel_radius)
                if is_opposite_valid:
                    window = extended_gaussian_heatmap[opposite_coords[0]-kernel_radius : opposite_coords[0]+kernel_radius+1, opposite_coords[1]-kernel_radius : opposite_coords[1]+kernel_radius+1]
                    value = apply_kernel(window, kernel)
                    extended_gaussian_heatmap[i, j] = value
                    filled_values[i, j] = 1
                    any_pixel_copied = True
                    count_filled += 1
        
        if count_filled == 0:
            if auto_increment_kernel: kernel_radius += 1
            else: break
    
    # Normalize the extended heatmap
    extended_gaussian_heatmap = extended_gaussian_heatmap/extended_gaussian_heatmap.sum()
    
    if return_filled: return extended_gaussian_heatmap, filled_values
    return extended_gaussian_heatmap

def batched_gaussian_symmetric_lines_completion(heatmaps, padding_target=None, symmetrize_original_heatmap=True, num_iters=0, num_iters_soft=1, kernel_radius=3, kernel_std=0.0, auto_increment_kernel=True, normalize=True):
    """Complete all the heatmaps in a given batch of heatmaps.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model with shape [B, E, H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H).
        symmetrize_original_heatmap (bool, default = False): Whether to start by symmetrizing all the pixels within the input heatmap. This step is enough in case the distribution's center is not close to one of the corners of the image.
        num_iters (int, default = 1): Number of times to repeat the process of trying to fill all rows and columns if possible given the all the filled pixels. This process converges to a stationary state where there are no more pixels to be filled (and thus the remaining iterations are ignored).
        num_iters_soft (int, default = 1): Number of times to repeat the process of trying to fill all rows and columns if possible by applying a kernel at the opposite coordinates.
        kernel_radius (int, default = 3): Number of pixels to be used as radius for constructing the kernel to apply during the soft iterations (kernel size = 2*kernel_radius + 1).
        kernel_std (float, default = 0.0): The std to be used for constructing the kernel to apply during the soft iterations. If std=0.0 then a uniform kernel is applied otherwise an inverted Gaussian kernel is applied.
        auto_increment_kernel (bool, default = True): Whether to increment the kernel_radius by 1 each time the soft iterations converge to a stationary state (no more pixels can be filled). By doing this, the soft iterations can keep on filling farther pixels.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        Extended heatmaps with completed Gaussian distributions and shape [B, E, top + H + bottom, left + W + rigth]
    """
    
    batches, locations = heatmaps.size()[0:2]
    all_heatmaps = []
    
    for batch_num in range(batches):
        batch_heatmaps = []
        
        for location_num in range(locations):
            extended_heatmap = gaussian_symmetric_lines_completion(heatmaps[batch_num, location_num], padding_target=padding_target, symmetrize_original_heatmap=symmetrize_original_heatmap, num_iters=num_iters, num_iters_soft=num_iters_soft, kernel_radius=kernel_radius, kernel_std=kernel_std, auto_increment_kernel=auto_increment_kernel, normalize=normalize)
            
            batch_heatmaps.append( extended_heatmap )
        
        batch_heatmaps =  torch.stack(batch_heatmaps, dim=0)
        all_heatmaps.append( batch_heatmaps )
    
    return torch.stack(all_heatmaps, dim=0)

#------------- SUPPORT FUNCTIONS FOR FAST GAUSSIAN HEATMAP COMPLETION (symmetric image implementation) ------------------#

def maximum_along_border(heatmap, not_filled_values, dilation_kernel):
    not_filled_values_dilated = not_filled_values.clone().unsqueeze(0).unsqueeze(0).float()
    not_filled_values_dilated = torch.nn.functional.conv2d(not_filled_values_dilated, dilation_kernel, padding=1)[0, 0] >= 1
    return heatmap[not_filled_values_dilated].max()

#------------------------------------------------------------------------------------------------------------------------#

def gaussian_symmetric_image(generated_heatmap, padding_target=None, dilation_iters=0, alpha=0.25, return_filled=False, make_plots=False, overwrite_original_pixels=False, normalize=True):
    """Perform fast Gaussian completion on a heatmap based on the symmetric lines that cross the center of the Gaussian distribution (maximum pixel). This implementation makes use of coordinates masks for fast completion with an optional dilation completion process.

    Args:
        generated_heatmap (torch.Tensor): Heatmap containing a Gaussian distribution to be completed/extended with shape [H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H). Maximum padding is (W, W, H, H).
        dilation_iters (int, default = 0): Number of times to repeat the process of heatmap dilation used to further extend the symmetrized heatmap.
        alpha (float, default = 0.25): Additional value to be added to the denumerator during the averaging of the pixels within the pixel dilation process.
        return_filled (bool, default = True): Whether to return a boolean mask with all the pixels that have been filled over the extended heatmap.
        make_plots (bool, default = True): Whether to show plots of the diverse heatmaps through the process.
        overwrite_original_pixels (bool, default = False): Whether to overwrite the pixels of the input heatmap. This can affect ellipse perfomance due to modifying the original heatmap.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        extended_gaussian_heatmap (torch.Tensor): Extended heatmap containing a completed Gaussian distribution with shape [top + H + bottom, left + W + right]
        filled_values (torch.Tensor): Optional boolean mask with all the pixels that have been filled over the extended heatmap with shape [top + H + bottom, left + W + right]
    """
    assert isinstance(dilation_iters, int),'Dilation iters must be an integer'
    assert dilation_iters>=0,'Dilation iters must be an positive'
    
    device = generated_heatmap.device
    h, w = generated_heatmap.shape[-2:]

    default_padding = (w,w,h,h)
    extended_gaussian_heatmap = torch.nn.functional.pad(generated_heatmap, default_padding).to(device)
    ext_h, ext_w = extended_gaussian_heatmap.shape[-2:]
    original_center = default_padding[2], default_padding[0]

    gaussian_center = generated_heatmap.argmax()
    gaussian_center = torch.Tensor( [gaussian_center//w, gaussian_center%w] ).to(device)

    x_mask = torch.arange(0, w).to(device)
    y_mask = torch.arange(0, h).to(device)
    
    x_mask = x_mask + 2*(gaussian_center[1] - x_mask) + w
    y_mask = y_mask + 2*(gaussian_center[0] - y_mask) + h
    
    x_mask = x_mask.unsqueeze(0).repeat(h, 1).long()
    y_mask = y_mask.unsqueeze(1).repeat(1, w).long()
    
    if overwrite_original_pixels:
        extended_gaussian_heatmap[y_mask, x_mask] = generated_heatmap
    else:
        not_filled_values = (extended_gaussian_heatmap<=0).to(device)
        temporal_extended_heatmap = torch.zeros(extended_gaussian_heatmap.shape).to(device)
        temporal_extended_heatmap[y_mask, x_mask] = generated_heatmap
        extended_gaussian_heatmap[not_filled_values] = temporal_extended_heatmap[not_filled_values]
    
    not_filled_values = (extended_gaussian_heatmap<=0).to(device)
    
    if make_plots:
        plt.imshow(extended_gaussian_heatmap.detach().cpu())
        plt.title('Extended heatmap before dilation')
        plt.show()
    
    if dilation_iters>0:
        dilation_kernel = torch.ones((1,1,3,3)).to(device)
        dilated_gaussian_heatmap = extended_gaussian_heatmap.clone().to(device).unsqueeze(0).unsqueeze(0)
        dilated_filled_values = (extended_gaussian_heatmap>0).to(device).unsqueeze(0).unsqueeze(0).float()
        for n in range(dilation_iters):
            dilated_gaussian_heatmap = torch.nn.functional.conv2d(dilated_gaussian_heatmap, dilation_kernel, padding=1)
            dilated_filled_values = torch.nn.functional.conv2d(dilated_filled_values, dilation_kernel, padding=1)
            
            dilated_filled_values = dilated_filled_values + alpha
            dilated_gaussian_heatmap = dilated_gaussian_heatmap / dilated_filled_values
            dilated_filled_values = (dilated_gaussian_heatmap>0).float()
            

        dilated_gaussian_heatmap = dilated_gaussian_heatmap[0,0]

        if make_plots:
            plt.title('Dilated heatmap')
            plt.imshow(dilated_gaussian_heatmap.detach().cpu())
            plt.show()
    
        max_heatmap_border = maximum_along_border(extended_gaussian_heatmap, not_filled_values, dilation_kernel).to(device)
        max_dilated = dilated_gaussian_heatmap[not_filled_values].max().to(device)
        dilated_gaussian_heatmap = dilated_gaussian_heatmap / max_dilated
        dilated_gaussian_heatmap = dilated_gaussian_heatmap * max_heatmap_border
        
        dilated_gaussian_heatmap[~not_filled_values] = 0
        extended_gaussian_heatmap = extended_gaussian_heatmap + dilated_gaussian_heatmap
        
    if padding_target is not None:
        left, right, top, bottom = padding_target
        assert left<=w and right<=w and top<=h and bottom<=h,'Maximum padding allowed is (W,W,H,H)'
        extended_gaussian_heatmap = extended_gaussian_heatmap[h-top:2*h+bottom, w-left:2*w+right]
    
    if normalize: extended_gaussian_heatmap = extended_gaussian_heatmap/extended_gaussian_heatmap.sum()
    
    filled_values = (extended_gaussian_heatmap>0).to(device)
    
    if make_plots:
        fig, ax = plt.subplots(1, 3, figsize=(15, 15))
        ax[0].imshow(generated_heatmap.detach().cpu())
        ax[0].set_title('Original heatmap')
        ax[1].imshow(filled_values.detach().cpu())
        ax[1].set_title('Filled pixels')
        ax[2].imshow(extended_gaussian_heatmap.detach().cpu())
        ax[2].set_title('Final extended heatmap')
        plt.show()
    
    if return_filled: return extended_gaussian_heatmap, filled_values
    return extended_gaussian_heatmap

def batched_gaussian_symmetric_image(heatmaps, padding_target=None, dilation_iters=0, alpha=0.25, overwrite_original_pixels=False, normalize=True):
    """Perform fast Gaussian completion on a batch of heatmaps based on the symmetric lines that cross the center of the Gaussian distribution (maximum pixel). This implementation makes use of coordinates masks for fast completion with an optional dilation completion process.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model with shape [B, E, H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H). Maximum padding is (W, W, H, H).
        dilation_iters (int, default = 0): Number of times to repeat the process of heatmap dilation used to further extend the symmetrized heatmap.
        alpha (float, default = 0.25): Additional value to be added to the denumerator during the averaging of the pixels within the pixel dilation process.
        overwrite_original_pixels (bool, default = False): Whether to overwrite the pixels of the input heatmap. This can affect ellipse perfomance due to modifying the original heatmap.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        extended_gaussian_heatmap (torch.Tensor): Extended heatmap containing a completed Gaussian distribution with shape [top + H + bottom, left + W + right]
        filled_values (torch.Tensor): Optional boolean mask with all the pixels that have been filled over the extended heatmap with shape [top + H + bottom, left + W + right]
    """
    
    batches, locations = heatmaps.size()[0:2]
    all_heatmaps = []
    
    for batch_num in range(batches):
        batch_heatmaps = []
        
        for location_num in range(locations):
            extended_heatmap = gaussian_symmetric_image(heatmaps[batch_num, location_num], padding_target=padding_target, dilation_iters=dilation_iters, alpha=alpha, overwrite_original_pixels=overwrite_original_pixels, normalize=normalize)
            
            batch_heatmaps.append( extended_heatmap )
        
        batch_heatmaps =  torch.stack(batch_heatmaps, dim=0)
        all_heatmaps.append( batch_heatmaps )
    
    return torch.stack(all_heatmaps, dim=0)

#---------------------------------------------------------------------------------------------------------------------------------------------------------------------#

def gaussian_symmetric_wave_image(generated_heatmap, padding_target=None, dilation_iters=0, alpha=0.25, return_filled=False, make_plots=False, overwrite_original_pixels=False, normalize=True):
    """Perform fast Gaussian completion on a heatmap based on the symmetric lines that cross the center of the Gaussian distribution (maximum pixel). This implementation makes use of coordinates masks for fast completion with an optional dilation completion process. The dilation completion process makes use of a wave mask that dilatates at every iteration ensuring a continuous extension of the heatmap.

    Args:
        generated_heatmap (torch.Tensor): Heatmap containing a Gaussian distribution to be completed/extended with shape [H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H). Maximum padding is (W, W, H, H).
        dilation_iters (int, default = 0): Number of times to repeat the process of heatmap dilation used to further extend the symmetrized heatmap.
        alpha (float, default = 0.25): Additional value to be added to the denumerator during the averaging of the pixels within the pixel dilation process.
        return_filled (bool, default = True): Whether to return a boolean mask with all the pixels that have been filled over the extended heatmap.
        make_plots (bool, default = True): Whether to show plots of the diverse heatmaps through the process.
        overwrite_original_pixels (bool, default = False): Whether to overwrite the pixels of the input heatmap. This can affect ellipse perfomance due to modifying the original heatmap.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        extended_gaussian_heatmap (torch.Tensor): Extended heatmap containing a completed Gaussian distribution with shape [top + H + bottom, left + W + right]
        filled_values (torch.Tensor): Optional boolean mask with all the pixels that have been filled over the extended heatmap with shape [top + H + bottom, left + W + right]
    """
    assert isinstance(dilation_iters, int),'Dilation iters must be an integer'
    assert dilation_iters>=0,'Dilation iters must be an positive'
    assert isinstance(alpha, float),'Alpha must be a float'
    assert alpha>0,'Alpha must be strictly positive'
    
    device = generated_heatmap.device
    h, w = generated_heatmap.shape[-2:]

    default_padding = (w,w,h,h)
    extended_gaussian_heatmap = torch.nn.functional.pad(generated_heatmap, default_padding).to(device)
    ext_h, ext_w = extended_gaussian_heatmap.shape[-2:]
    original_center = default_padding[2], default_padding[0]

    gaussian_center = generated_heatmap.argmax()
    gaussian_center = torch.Tensor( [gaussian_center//w, gaussian_center%w] ).to(device)

    x_mask = torch.arange(0, w).to(device)
    y_mask = torch.arange(0, h).to(device)
    
    x_mask = x_mask + 2*(gaussian_center[1] - x_mask) + w
    y_mask = y_mask + 2*(gaussian_center[0] - y_mask) + h
    
    x_mask = x_mask.unsqueeze(0).repeat(h, 1).long()
    y_mask = y_mask.unsqueeze(1).repeat(1, w).long()
    
    if overwrite_original_pixels:
        extended_gaussian_heatmap[y_mask, x_mask] = generated_heatmap
    else:
        not_filled_values = (extended_gaussian_heatmap<=0).to(device)
        temporal_extended_heatmap = torch.zeros(extended_gaussian_heatmap.shape).to(device)
        temporal_extended_heatmap[y_mask, x_mask] = generated_heatmap
        extended_gaussian_heatmap[not_filled_values] = temporal_extended_heatmap[not_filled_values]
    
    not_filled_values = (extended_gaussian_heatmap<=0).to(device)
    
    if make_plots:
        plt.imshow(extended_gaussian_heatmap.detach().cpu())
        plt.title('Extended heatmap before dilation')
        plt.show()
    
    if dilation_iters>0:
        dilation_kernel = torch.ones((1,1,3,3)).to(device)
        dilated_gaussian_heatmap = extended_gaussian_heatmap.clone().to(device).unsqueeze(0).unsqueeze(0)
        wave_gaussian_heatmap = torch.zeros(dilated_gaussian_heatmap.shape).to(device)
        boolean_dilated_values = (extended_gaussian_heatmap>0).to(device).unsqueeze(0).unsqueeze(0).float()
        dilated_filled_values = boolean_dilated_values.clone().to(device)
        
        for n in range(dilation_iters):
            dilated_gaussian_heatmap = torch.nn.functional.conv2d(dilated_gaussian_heatmap, dilation_kernel, padding=1)
            dilated_filled_values = torch.nn.functional.conv2d(dilated_filled_values, dilation_kernel, padding=1)
            new_boolean_dilated_values = torch.clamp( torch.nn.functional.conv2d(boolean_dilated_values, dilation_kernel, padding=1), 0, 1)
            wave_idxs = ((new_boolean_dilated_values - boolean_dilated_values)==1).to(device)
            
            boolean_dilated_values = new_boolean_dilated_values
            dilated_filled_values = dilated_filled_values + alpha
            dilated_gaussian_heatmap = dilated_gaussian_heatmap / dilated_filled_values
            dilated_filled_values = (dilated_gaussian_heatmap>0).to(device).float()
            
            wave_gaussian_heatmap[wave_idxs] = dilated_gaussian_heatmap[wave_idxs]


        dilated_gaussian_heatmap = dilated_gaussian_heatmap[0,0]
        wave_gaussian_heatmap = wave_gaussian_heatmap[0,0]

        if make_plots:
            plt.title('Dilated heatmap')
            plt.imshow(dilated_gaussian_heatmap.detach().cpu())
            plt.show()
            
            plt.title('Wave dilated heatmap')
            plt.imshow(wave_gaussian_heatmap.detach().cpu())
            plt.show()
    
        extended_gaussian_heatmap = extended_gaussian_heatmap + wave_gaussian_heatmap
        
        
    if padding_target is not None:
        left, right, top, bottom = padding_target
        assert left<=w and right<=w and top<=h and bottom<=h,'Maximum padding allowed is (W,W,H,H)'
        extended_gaussian_heatmap = extended_gaussian_heatmap[h-top:2*h+bottom, w-left:2*w+right]
    
    if normalize: extended_gaussian_heatmap = extended_gaussian_heatmap/extended_gaussian_heatmap.sum()
    
    filled_values = (extended_gaussian_heatmap>0).to(device)
    
    if make_plots:
        fig, ax = plt.subplots(1, 3, figsize=(15, 15))
        ax[0].imshow(generated_heatmap.detach().cpu())
        ax[0].set_title('Original heatmap')
        ax[1].imshow(filled_values.detach().cpu())
        ax[1].set_title('Filled pixels')
        ax[2].imshow(extended_gaussian_heatmap.detach().cpu())
        ax[2].set_title('Final extended heatmap')
        plt.show()
    
    if return_filled: return extended_gaussian_heatmap, filled_values
    return extended_gaussian_heatmap

def batched_gaussian_symmetric_wave_image(heatmaps, padding_target=None, dilation_iters=0, alpha=0.25, overwrite_original_pixels=False, normalize=True):
    """Perform fast Gaussian completion on a batch of heatmaps based on the symmetric lines that cross the center of the Gaussian distribution (maximum pixel). This implementation makes use of coordinates masks for fast completion with an optional dilation completion process.

    Args:
        heatmaps (torch.Tensor): Heatmaps generated by the model with shape [B, E, H, W]
        padding_target (tuple, default = None): Padding to be added and filled to the input heatmap in the form of the tuple (left, right, top, bottom). If None, then the tuple defaults to (W, W, H, H). Maximum padding is (W, W, H, H).
        dilation_iters (int, default = 0): Number of times to repeat the process of heatmap dilation used to further extend the symmetrized heatmap.
        alpha (float, default = 0.25): Additional value to be added to the denumerator during the averaging of the pixels within the pixel dilation process.
        overwrite_original_pixels (bool, default = False): Whether to overwrite the pixels of the input heatmap. This can affect ellipse perfomance due to modifying the original heatmap.
        normalize (bool, default = True): Whether to normalize the extended heatmap to be returned.

    Returns:
        extended_gaussian_heatmap (torch.Tensor): Extended heatmap containing a completed Gaussian distribution with shape [top + H + bottom, left + W + right]
        filled_values (torch.Tensor): Optional boolean mask with all the pixels that have been filled over the extended heatmap with shape [top + H + bottom, left + W + right]
    """
    
    batches, locations = heatmaps.size()[0:2]
    all_heatmaps = []
    
    for batch_num in range(batches):
        batch_heatmaps = []
        
        for location_num in range(locations):
            extended_heatmap = gaussian_symmetric_wave_image(heatmaps[batch_num, location_num], padding_target=padding_target, dilation_iters=dilation_iters, alpha=alpha, overwrite_original_pixels=overwrite_original_pixels, normalize=normalize)
            
            batch_heatmaps.append( extended_heatmap )
        
        batch_heatmaps =  torch.stack(batch_heatmaps, dim=0)
        all_heatmaps.append( batch_heatmaps )
    
    return torch.stack(all_heatmaps, dim=0)

